{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scratchpad",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/parulnith/GenAI/blob/main/Apps/AI_card_generator.ipynb#scrollTo=SFM-euGUkkMj)\n"
      ],
      "metadata": {
        "id": "GH8Njs6OR8Mm"
      }
    },
    {
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "cell_type": "markdown",
      "source": [
        "# 🎨 AI-Powered Greeting Card Generator\n",
        "\n",
        "## 📌 About This Notebook\n",
        "This notebook demonstrates how to **create an AI-powered greeting card generator** using **Gradio** and **Google Gemini AI**.\n",
        "\n",
        "You will be able to:\n",
        "- Generate **custom greeting cards** with a message.\n",
        "- Use **Google Gemini AI** to create **aesthetic card designs**.\n",
        "- Deploy a **Gradio web app** in **Colab/Jupyter Notebook**.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps to Use This Notebook\n",
        "* Run all the cells in this notebook.\n",
        "* Enter your Google Gemini API Key in the designated section.\n",
        "* Click the Gradio link (which will be generated) to access your web app.\n",
        "* Enter details (like occasion, sender name, and recipient name).\n",
        "* Click \"Generate Greeting Card\" to see the AI-created card!\n",
        "* Click \"Generate a New Card\" to reset the fields.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lVX2vrrJkXIk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 📌 Step 1: Install Required Libraries\n",
        "Run the following cell to **install Gradio and Google Gemini AI**:"
      ],
      "metadata": {
        "id": "rF6_Nth-kidk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install gradio google-genai --quiet\n"
      ],
      "metadata": {
        "id": "SFM-euGUkkMj",
        "outputId": "d202f2ba-26fa-4679-816a-a90994064056",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🔑 Step 1: Set Up Google Gemini API Key\n",
        "Google Gemini AI requires an API key to generate images. Follow these steps:\n",
        "\n",
        "* Go to Google AI Studio → https://aistudio.google.com\n",
        "* Sign in with your Google account and get an API key.\n",
        "* Use the secrets manager to securely store your API key:\n"
      ],
      "metadata": {
        "id": "a9ZbBTbTlHSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set API key securely\n",
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n"
      ],
      "metadata": {
        "id": "81emTFX1lVWD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Import Necessary Libraries\n",
        "## Run the following cell to import required libraries:"
      ],
      "metadata": {
        "id": "5zP4PJdNmE1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gradio as gr\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "\n",
        "# Ensure 'static' directory exists to store generated images\n",
        "output_dir = \"/content/static\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "S6Y6vFFMmJKU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Define Helper Functions\n",
        "These functions handle image generation using Google Gemini AI."
      ],
      "metadata": {
        "id": "5C6RKzH3mM6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(occasion, sender_name, recipient_name, custom_message):\n",
        "    client = genai.Client(\n",
        "        api_key=os.environ.get(\"GEMINI_API_KEY\"),\n",
        "    )\n",
        "\n",
        "    model = \"gemini-2.0-flash-exp-image-generation\"\n",
        "\n",
        "    # Predefined prompts for different occasions\n",
        "    if not custom_message:\n",
        "        if occasion == \"Birthday\":\n",
        "            prompt = (\n",
        "                f\"Generate a design for a birthday card with beautiful floral decorations. \"\n",
        "                f\"The text should be large and say:\\n\\n\"\n",
        "                f\"Happy Birthday, {recipient_name}!\\n\\n\"\n",
        "                f\"Wishing you a day filled with joy, laughter, and all your favorite things.\\n\"\n",
        "                f\"May this next year be your best one yet, bringing you exciting adventures and wonderful memories.\\n\"\n",
        "                f\"Cheers to you!\\n\\n\"\n",
        "                f\"With love, {sender_name}.\"\n",
        "            )\n",
        "        elif occasion == \"Anniversary\":\n",
        "            prompt = (\n",
        "                f\"Create an elegant anniversary card with golden details and a heartfelt message. \"\n",
        "                f\"The text should be large and say:\\n\\n\"\n",
        "                f\"Happy Anniversary, {recipient_name}!\\n\\n\"\n",
        "                f\"Celebrating another year of love, laughter, and cherished moments together.\\n\"\n",
        "                f\"Wishing you endless happiness and many more beautiful years ahead.\\n\"\n",
        "                f\"Cheers to love!\\n\\n\"\n",
        "                f\"With best wishes, {sender_name}.\"\n",
        "            )\n",
        "        elif occasion == \"Christmas\":\n",
        "            prompt = (\n",
        "                f\"Design a festive Christmas card with snowy landscapes and warm holiday colors. \"\n",
        "                f\"The text should be large and say:\\n\\n\"\n",
        "                f\"Merry Christmas, {recipient_name}!\\n\\n\"\n",
        "                f\"May your holidays be filled with joy, love, and the magic of the season.\\n\"\n",
        "                f\"Wishing you peace, happiness, and wonderful moments with your loved ones.\\n\"\n",
        "                f\"Warmest wishes for a joyful Christmas!\\n\\n\"\n",
        "                f\"With love, {sender_name}.\"\n",
        "            )\n",
        "        elif occasion == \"New Year\":\n",
        "            prompt = (\n",
        "                f\"Generate a vibrant New Year greeting card with fireworks and celebration themes. \"\n",
        "                f\"The text should be large and say:\\n\\n\"\n",
        "                f\"Happy New Year, {recipient_name}!\\n\\n\"\n",
        "                f\"Wishing you a year filled with success, happiness, and new opportunities.\\n\"\n",
        "                f\"May each day bring you closer to your dreams and be filled with exciting possibilities.\\n\"\n",
        "                f\"Cheers to a fantastic year ahead!\\n\\n\"\n",
        "                f\"Best wishes, {sender_name}.\"\n",
        "            )\n",
        "        else:\n",
        "            prompt = (\n",
        "                f\"Create a heartfelt greeting card with a soft, pastel background. \"\n",
        "                f\"The text should be large and say:\\n\\n\"\n",
        "                f\"Thinking of You, {recipient_name}!\\n\\n\"\n",
        "                f\"Just a little note to remind you how special and amazing you are.\\n\"\n",
        "                f\"Sending you warm thoughts, love, and positivity your way.\\n\"\n",
        "                f\"Hope your day is as wonderful as you are!\\n\\n\"\n",
        "                f\"With warm wishes, {sender_name}.\"\n",
        "            )\n",
        "    else:\n",
        "        prompt = f\"Generate a greeting card with a nice background based on and clear text that says:\\n\\nDear {recipient_name},\\n\\n{custom_message}\\n\\nFrom, {sender_name}.\"\n",
        "\n",
        "    contents = [\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[types.Part.from_text(text=prompt)],\n",
        "        ),\n",
        "    ]\n",
        "    generate_content_config = types.GenerateContentConfig(\n",
        "        temperature=1,\n",
        "        top_p=0.95,\n",
        "        top_k=40,\n",
        "        max_output_tokens=8192,\n",
        "        response_modalities=[\"text\", \"image\"],\n",
        "    )\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=model,\n",
        "        contents=contents,\n",
        "        config=generate_content_config,\n",
        "    )\n",
        "\n",
        "    for candidate in response.candidates:\n",
        "        for part in candidate.content.parts:\n",
        "            if part.inline_data:\n",
        "                file_name = f\"static/{str(occasion).lower()}_card.png\"\n",
        "                save_binary_file(file_name, part.inline_data.data)\n",
        "                return file_name\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "DBIZhWq4mODA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Create a Gradio Interface\n",
        "This creates a user-friendly web app to interact with the AI."
      ],
      "metadata": {
        "id": "yl2AxBOdmV-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to interface Gradio with our AI model\n",
        "def gradio_interface(occasion, sender_name, recipient_name, custom_message):\n",
        "    image_path = generate(occasion, sender_name, recipient_name, custom_message)\n",
        "    if image_path:\n",
        "        return image_path  # Returning the image file path\n",
        "    else:\n",
        "        return None  # Return None if image generation fails\n",
        "\n",
        "# Create a Gradio app with a simple user interface\n",
        "with gr.Blocks(theme=gr.themes.Citrus()) as demo:\n",
        "    gr.Markdown(\"<center><h1>🎨 Greeting Card Generator 🎨</h1></center>\")  # App Title\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            # Dropdown for selecting the occasion\n",
        "            occasion = gr.Dropdown(\n",
        "                label=\"Choose an Occasion\",\n",
        "                choices=[\"Birthday\", \"Christmas\", \"New Year\", \"Anniversary\", \"Others\"],\n",
        "                value=\"Birthday\"\n",
        "            )\n",
        "            # Input fields for sender's and recipient's name\n",
        "            sender_name = gr.Textbox(label=\"Sender's Name\")\n",
        "            recipient_name = gr.Textbox(label=\"Recipient's Name\")\n",
        "            # Custom message input\n",
        "            custom_message = gr.Textbox(label=\"Custom Message (Leave blank for auto-generated)\")\n",
        "            # Buttons for generating and resetting\n",
        "            generate_button = gr.Button(\"Generate Greeting Card\")\n",
        "            reset_button = gr.Button(\"Generate a New Card\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_image = gr.Image(label=\"Generated Greeting Card\",width=600, height=550)\n",
        "\n",
        "    # When the Generate button is clicked, run the `gradio_interface` function\n",
        "    generate_button.click(\n",
        "        fn=gradio_interface,\n",
        "        inputs=[occasion, sender_name, recipient_name, custom_message],\n",
        "        outputs=output_image\n",
        "    )\n",
        "\n",
        "    # When the Reset button is clicked, clear all input fields\n",
        "    reset_button.click(\n",
        "        fn=lambda: (\"Birthday\", \"\", \"\", \"\"),\n",
        "        inputs=[],\n",
        "        outputs=[occasion, sender_name, recipient_name, custom_message]\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ce-nKcF7mYR8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Run the Gradio App\n",
        "This command launches the Gradio web app and provides a public link."
      ],
      "metadata": {
        "id": "VODSIZVKmed4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch the Gradio app with sharing enabled.\n",
        "demo.launch(share=True,debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "qQpAoQjSmfc_",
        "outputId": "cd9b0bb2-8b44-402d-9a47-c857951cebbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://4333f800b55e33b528.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4333f800b55e33b528.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Af1OX-ZvqyQd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}